{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eTHpTjbFyTHs"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# Step 1: Authentication & Setup\n",
        "# ==========================================\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Set your variables\n",
        "PROJECT_ID = 'bookbridge-477802'\n",
        "BUCKET_NAME = 'book_bridge'\n",
        "SOURCE_PATH = f\"gs://{BUCKET_NAME}/item2vec_training_data\"\n",
        "DEST_MODEL_PATH = f\"gs://{BUCKET_NAME}/models/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the project for gsutil\n",
        "!gcloud config set project {PROJECT_ID}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K8dOCWpyk4V",
        "outputId": "c02ae309-edc0-4cd1-d580-62c87bd54350"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Step 2: Load & Prepare Data\n",
        "# ==========================================\n",
        "import os\n",
        "\n",
        "# Create a local directory\n",
        "os.makedirs(\"data_parts\", exist_ok=True)\n",
        "\n",
        "print(\"Downloading training data parts from GCS...\")\n",
        "# -m enables multi-threaded download (faster)\n",
        "!gsutil -m cp -r {SOURCE_PATH}/*.gz ./data_parts/\n",
        "\n",
        "print(\"Merging and decompressing files...\")\n",
        "# TRICK: We use zcat to decompress AND concatenate all parts into one file\n",
        "# This creates a single 'corpus.txt' that Gensim can read easily.\n",
        "!zcat ./data_parts/*.gz > corpus.txt\n",
        "\n",
        "# Verify the data looks right (User ID sequences)\n",
        "print(\"\\n--- First 3 lines of Corpus ---\")\n",
        "!head -n 3 corpus.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z0_d2ziyp9n",
        "outputId": "f01d3cd8-d4d2-450c-fdf2-5ad0748c2525"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading training data parts from GCS...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00001-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00002-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00006-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00003-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00007-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00000-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00004-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00005-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00008-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00009-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00010-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00011-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "Copying gs://book_bridge/item2vec_training_data/part-00012-a2f627d1-b68a-494a-88b6-5e59e18cf828-c000.txt.gz...\n",
            "- [13/13 files][ 24.2 MiB/ 24.2 MiB] 100% Done   2.0 MiB/s ETA 00:00:00         \n",
            "Operation completed over 13 objects/24.2 MiB.                                    \n",
            "Merging and decompressing files...\n",
            "\n",
            "--- First 3 lines of Corpus ---\n",
            "B017G93BSK B07ZY839HC B08KGZ2FK8 B08XMCMCXT B00CJH944U B08HR1CF8B B086T371T7 B00UG9E1FK B088CSGGHH\n",
            "B00AVMTF8U 0425158543 0762782811 B00IJXAM80\n",
            "0764152319 1554512115 0375846212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSjkdZZlzMhj",
        "outputId": "a8611bb8-fc34-44ff-e7b9-f273ce7b0e52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Step 3: Train Item2Vec (Word2Vec)\n",
        "# ==========================================\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.word2vec import LineSentence\n",
        "import multiprocessing\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "\n",
        "# Stream the corpus from disk\n",
        "sentences = LineSentence(\"corpus.txt\")\n",
        "\n",
        "# Train the model\n",
        "# vector_size=100: Standard for recommendation\n",
        "# window=5: Context window (how many books before/after to consider)\n",
        "# min_count=3: Ignore books that appear less than 3 times (filters noise)\n",
        "# negative sampling=10: Increase the embedding space\n",
        "# sg=1: Apply Skip-Gram method since the data is sparse\n",
        "model = Word2Vec(\n",
        "    sentences=sentences,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=3,\n",
        "    sg=1,\n",
        "    negative=10,\n",
        "    workers=multiprocessing.cpu_count(),\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "print(f\"Training Complete! Vocab size: {len(model.wv.index_to_key)} books\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrmRN6I5yYLE",
        "outputId": "823c5ebf-a939-479b-8a97-017af017a0e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training...\n",
            "Training Complete! Vocab size: 99667 books\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Step 4: Save & Upload Artifacts\n",
        "# ==========================================\n",
        "\n",
        "# 1. Save the Lightweight KeyedVectors (Best for API)\n",
        "model.wv.save(\"item_embeddings.kv\")\n",
        "\n",
        "# 2. Save the Full Model (Optional - Good for retraining later)\n",
        "model.save(\"item2vec_full.model\")\n",
        "\n",
        "print(f\"Uploading models to {DEST_MODEL_PATH}...\")\n",
        "!gsutil cp item_embeddings.kv {DEST_MODEL_PATH}\n",
        "!gsutil cp item2vec_full.model {DEST_MODEL_PATH}\n",
        "\n",
        "print(\"‚úÖ DONE. Your model is safe in GCS.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF5Psap4y9an",
        "outputId": "2db59b2e-fec4-4768-ee1e-ba1209efe478"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading models to gs://book_bridge/models/...\n",
            "Copying file://item_embeddings.kv [Content-Type=application/octet-stream]...\n",
            "/\n",
            "Operation completed over 1 objects/41.2 MiB.                                     \n",
            "Copying file://item2vec_full.model [Content-Type=application/octet-stream]...\n",
            "|\n",
            "Operation completed over 1 objects/79.2 MiB.                                     \n",
            "‚úÖ DONE. Your model is safe in GCS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "from google.colab import auth\n",
        "\n",
        "# ==========================================\n",
        "# 1. Setup & Authentication\n",
        "# ==========================================\n",
        "auth.authenticate_user()\n",
        "\n",
        "# TODO: Replace with your actual bucket name\n",
        "BUCKET_NAME = \"book_bridge\"\n",
        "PROJECT_ID = \"bookbridge-477802\"\n",
        "\n",
        "# Paths\n",
        "REMOTE_SOURCE_DIR = f\"gs://{BUCKET_NAME}/filtered_metadata\" # Spark output folder\n",
        "LOCAL_META_FILE = \"metadata.jsonl\"\n",
        "LOCAL_INDEX_FILE = \"title_to_id_index.json\"\n",
        "REMOTE_DEST_PATH = f\"gs://{BUCKET_NAME}/indexes/{LOCAL_INDEX_FILE}\"\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "\n",
        "# ==========================================\n",
        "# 2. Download Data from Spark Folder\n",
        "# ==========================================\n",
        "print(f\"Downloading metadata from {REMOTE_SOURCE_DIR}...\")\n",
        "\n",
        "# Spark creates a folder. We use wildcard *.json to grab the actual data file\n",
        "# and rename it to 'metadata.jsonl' locally for easy processing.\n",
        "!gsutil cp {REMOTE_SOURCE_DIR}/*.json {LOCAL_META_FILE}\n",
        "\n",
        "print(\"Download complete.\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. Build the Normalized Lookup Map\n",
        "# ==========================================\n",
        "def normalize_title(title):\n",
        "    \"\"\"\n",
        "    Standardizes titles for fuzzy matching.\n",
        "    Input:  \"Harry Potter and the Sorcerer's Stone (Book 1)\"\n",
        "    Output: \"harrypotterandthesorcerersstonebook1\"\n",
        "    \"\"\"\n",
        "    if not title: return \"\"\n",
        "    # Lowercase\n",
        "    clean = title.lower()\n",
        "    # Remove all non-alphanumeric characters (spaces, punctuation, emojis)\n",
        "    clean = re.sub(r'[^a-z0-9]', '', clean)\n",
        "    return clean\n",
        "\n",
        "title_to_asin_map = {}\n",
        "count = 0\n",
        "duplicates = 0\n",
        "\n",
        "print(\"Building index (this may take 1-2 minutes)...\")\n",
        "\n",
        "with open(LOCAL_META_FILE, 'r') as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            item = json.loads(line)\n",
        "            asin = item.get('asin')\n",
        "            title = item.get('title')\n",
        "\n",
        "            if title and asin:\n",
        "                # Create the \"slug\" key\n",
        "                key = normalize_title(title)\n",
        "\n",
        "                # Collision Strategy: First entry wins (usually the most popular if sorted)\n",
        "                if key not in title_to_asin_map:\n",
        "                    title_to_asin_map[key] = asin\n",
        "                else:\n",
        "                    duplicates += 1\n",
        "\n",
        "                count += 1\n",
        "                if count % 20000 == 0:\n",
        "                    print(f\"Processed {count} books...\")\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            continue\n",
        "\n",
        "print(f\"\\n--- Index Build Complete ---\")\n",
        "print(f\"Total Books Processed: {count}\")\n",
        "print(f\"Unique Titles in Index: {len(title_to_asin_map)}\")\n",
        "print(f\"Duplicate Titles Skipped: {duplicates}\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. Save & Upload\n",
        "# ==========================================\n",
        "print(f\"Saving to {LOCAL_INDEX_FILE}...\")\n",
        "with open(LOCAL_INDEX_FILE, 'w') as out:\n",
        "    json.dump(title_to_asin_map, out)\n",
        "\n",
        "print(f\"Uploading to GCS: {REMOTE_DEST_PATH}...\")\n",
        "!gsutil cp {LOCAL_INDEX_FILE} {REMOTE_DEST_PATH}\n",
        "\n",
        "print(\"‚úÖ SUCCESS: Index is ready for your API.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLcZ_3g1skcy",
        "outputId": "794c41d1-a53b-439a-d95b-6e6a1069dfb5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "Downloading metadata from gs://book_bridge/filtered_metadata...\n",
            "Copying gs://book_bridge/filtered_metadata/part-00000-4a0f39af-08f9-4855-85a1-d8b1c1a3ef89-c000.json...\n",
            "==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "| [1 files][473.0 MiB/473.0 MiB]                                                \n",
            "Operation completed over 1 objects/473.0 MiB.                                    \n",
            "Download complete.\n",
            "Building index (this may take 1-2 minutes)...\n",
            "Processed 20000 books...\n",
            "Processed 40000 books...\n",
            "Processed 60000 books...\n",
            "Processed 80000 books...\n",
            "\n",
            "--- Index Build Complete ---\n",
            "Total Books Processed: 99797\n",
            "Unique Titles in Index: 92073\n",
            "Duplicate Titles Skipped: 7724\n",
            "Saving to title_to_id_index.json...\n",
            "Uploading to GCS: gs://book_bridge/indexes/title_to_id_index.json...\n",
            "Copying file://title_to_id_index.json [Content-Type=application/json]...\n",
            "/ [1 files][  5.7 MiB/  5.7 MiB]                                                \n",
            "Operation completed over 1 objects/5.7 MiB.                                      \n",
            "‚úÖ SUCCESS: Index is ready for your API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "urTRWeefjrY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import os\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# ==========================================\n",
        "# 1. Configuration\n",
        "# ==========================================\n",
        "BUCKET_NAME = 'book_bridge' # Replace with your bucket\n",
        "MODEL_FILE = \"item_embeddings.kv\"\n",
        "REMOTE_PATH = f\"gs://{BUCKET_NAME}/models/{MODEL_FILE}\"\n",
        "\n",
        "# ==========================================\n",
        "# 2. Download from GCS\n",
        "# ==========================================\n",
        "print(f\"Downloading model from {REMOTE_PATH}...\")\n",
        "\n",
        "# Check if file already exists locally to save time\n",
        "if not os.path.exists(MODEL_FILE):\n",
        "    !gsutil cp {REMOTE_PATH} .\n",
        "    print(\"Download complete.\")\n",
        "else:\n",
        "    print(\"Model file already exists locally.\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. Load into Gensim\n",
        "# ==========================================\n",
        "print(\"Loading vectors into memory...\")\n",
        "\n",
        "# We use KeyedVectors.load() because we saved it as .kv\n",
        "# mmap='r' is optional but great for speed (memory mapping)\n",
        "model_vectors = KeyedVectors.load(MODEL_FILE, mmap='r')\n",
        "\n",
        "print(f\"Model loaded successfully!\")\n",
        "print(f\"Vocabulary size: {len(model_vectors.index_to_key)}\")\n",
        "\n",
        "# ==========================================\n",
        "# 4. Test the Model (Sanity Check)\n",
        "# ==========================================\n",
        "# Pick the most popular book (index 0) to test\n",
        "test_book = model_vectors.index_to_key[0]\n",
        "print(f\"\\nTest Recommendation for Book ID: {test_book}\")\n",
        "\n",
        "similar_items = model_vectors.most_similar(test_book, topn=5)\n",
        "for item_id, score in similar_items:\n",
        "    print(f\"- {item_id} (Score: {score:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDY1Ow7QKPh6",
        "outputId": "0f2bb3c7-022c-44f4-bde3-368bb0f3bb7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model from gs://book_bridge/models/item_embeddings.kv...\n",
            "Copying gs://book_bridge/models/item_embeddings.kv...\n",
            "- [1 files][ 41.2 MiB/ 41.2 MiB]                                                \n",
            "Operation completed over 1 objects/41.2 MiB.                                     \n",
            "Download complete.\n",
            "Loading vectors into memory...\n",
            "Model loaded successfully!\n",
            "Vocabulary size: 99667\n",
            "\n",
            "Test Recommendation for Book ID: B00L9B7IKE\n",
            "- B0027MJU00 (Score: 0.6783)\n",
            "- B00AEDDSZW (Score: 0.6262)\n",
            "- B0151YQUTE (Score: 0.6215)\n",
            "- B00IB5BSBG (Score: 0.6210)\n",
            "- B00KU4PW86 (Score: 0.6056)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# ==========================================\n",
        "# 1. Setup Resources\n",
        "# ==========================================\n",
        "print(\"‚è≥ Loading resources into memory...\")\n",
        "\n",
        "# A. Load the Title -> ID Index\n",
        "with open(\"title_to_id_index.json\", \"r\") as f:\n",
        "    title_to_id = json.load(f)\n",
        "\n",
        "# B. Load the Vectors\n",
        "model = KeyedVectors.load(\"item_embeddings.kv\", mmap='r')\n",
        "\n",
        "# C. Build ID -> Title Map (for display only)\n",
        "# We need this to turn the recommended IDs (e.g. \"B001...\") back into Titles\n",
        "id_to_title = {}\n",
        "with open(\"metadata.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            item = json.loads(line)\n",
        "            id_to_title[item['asin']] = item['title']\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "print(f\"‚úÖ Resources Ready. Catalog size: {len(title_to_id)} titles.\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. Input from OpenAI (Titles Only)\n",
        "# ==========================================\n",
        "openai_titles = [\n",
        "    \"Dune\",\n",
        "    \"The Name of the Wind\",\n",
        "    \"The Left Hand of Darkness\",\n",
        "    \"Mistborn: The Final Empire\",\n",
        "    \"The Way of Kings\",\n",
        "    \"Hyperion\",\n",
        "    \"The Lies of Locke Lamora\",\n",
        "    \"The Fifth Season\",\n",
        "    \"Neuromancer\",\n",
        "    \"The Blade Itself\"\n",
        "]\n",
        "\n",
        "# ==========================================\n",
        "# 3. The Recommender Logic\n",
        "# ==========================================\n",
        "def normalize_title(title):\n",
        "    \"\"\"Must match the logic used to build the index exactly\"\"\"\n",
        "    if not title: return \"\"\n",
        "    return re.sub(r'[^a-z0-9]', '', title.lower())\n",
        "\n",
        "print(\"\\n--- üöÄ Starting Recommendation Pipeline ---\\n\")\n",
        "\n",
        "hits = 0\n",
        "\n",
        "for raw_title in openai_titles:\n",
        "    # 1. Normalize\n",
        "    search_key = normalize_title(raw_title)\n",
        "\n",
        "    # 2. Lookup in Index (Validation)\n",
        "    if search_key in title_to_id:\n",
        "        book_id = title_to_id[search_key]\n",
        "        hits += 1\n",
        "        print(f\"‚úÖ MATCH: '{raw_title}' -> ID: {book_id}\")\n",
        "\n",
        "        # 3. Vector Search (Item2Vec)\n",
        "        # Check if this specific book ID survived the training filter (min_count)\n",
        "        if book_id in model:\n",
        "            # Get top 5 recommendations\n",
        "            recommendations = model.most_similar(book_id, topn=5)\n",
        "\n",
        "            print(f\"   ‚Ü≥ Based on this, you might like:\")\n",
        "            for rank, (rec_id, score) in enumerate(recommendations, 1):\n",
        "                # Convert ID back to Title for display\n",
        "                rec_title = id_to_title.get(rec_id, \"[Title Not in Metadata]\")\n",
        "                print(f\"      {rank}. {rec_title} (Sim: {score:.2f})\")\n",
        "        else:\n",
        "            print(f\"   ‚ö†Ô∏è ID found, but it had too few interactions to form a vector.\")\n",
        "\n",
        "    else:\n",
        "        # This usually happens if the book is too new (e.g. published after 2014/2018)\n",
        "        # or if the title spelling in Amazon is slightly different.\n",
        "        print(f\"‚ùå MISS: '{raw_title}' (Key: {search_key}) - Not in Top 100k Catalog.\")\n",
        "\n",
        "print(f\"\\n--- Summary: Found {hits}/{len(openai_titles)} books ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTD8cP4LjPwM",
        "outputId": "2e90c1ca-002e-4e30-8e9c-e43b5ca9a4e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Loading resources into memory...\n",
            "‚úÖ Resources Ready. Catalog size: 92073 titles.\n",
            "\n",
            "--- üöÄ Starting Recommendation Pipeline ---\n",
            "\n",
            "‚úÖ MATCH: 'Dune' -> ID: 044100590X\n",
            "   ‚Ü≥ Based on this, you might like:\n",
            "      1. Shadow of the Hegemon (The Shadow Series) (Sim: 0.98)\n",
            "      2. The End of Eternity: A Novel (Sim: 0.98)\n",
            "      3. The Anubis Gates (Ace Science Fiction) (Sim: 0.98)\n",
            "      4. The Arabian Nights: Tales of 1,001 Nights: Volume 1 (Penguin Classics) (Sim: 0.98)\n",
            "      5. Weaveworld (Sim: 0.98)\n",
            "‚úÖ MATCH: 'The Name of the Wind' -> ID: 075640407X\n",
            "   ‚Ü≥ Based on this, you might like:\n",
            "      1. Red Country (Sim: 0.98)\n",
            "      2. The Wise Man's Fear (Kingkiller Chronicles, Day 2) (Sim: 0.97)\n",
            "      3. The Name of the Wind (Sim: 0.97)\n",
            "      4. Last Argument of Kings (First Law: Book Three) (Sim: 0.97)\n",
            "      5. The Emperor's Soul (Sim: 0.97)\n",
            "‚ùå MISS: 'The Left Hand of Darkness' (Key: thelefthandofdarkness) - Not in Top 100k Catalog.\n",
            "‚úÖ MATCH: 'Mistborn: The Final Empire' -> ID: 076531178X\n",
            "   ‚Ü≥ Based on this, you might like:\n",
            "      1. The Amulet of Samarkand (The Bartimaeus Trilogy, Book 1) (Sim: 0.97)\n",
            "      2. Warbreaker (Sim: 0.97)\n",
            "      3. Warbreaker (Sci Fi Essential Books) (Sim: 0.97)\n",
            "      4. The Republic of Thieves (Gentleman Bastards) (Sim: 0.97)\n",
            "      5. Night Angel: The Complete Trilogy (The Night Angel Trilogy) (Sim: 0.97)\n",
            "‚úÖ MATCH: 'The Way of Kings' -> ID: 0765365278\n",
            "   ‚Ü≥ Based on this, you might like:\n",
            "      1. Words of Radiance: Book Two of the Stormlight Archive (The Stormlight Archive, 2) (Sim: 0.97)\n",
            "      2. The Way of Kings: Book One of the Stormlight Archive (The Stormlight Archive, 1) (Sim: 0.96)\n",
            "      3. Warbreaker (Sim: 0.95)\n",
            "      4. Words of Radiance (The Stormlight Archive, Book 2) (The Stormlight Archive, 2) (Sim: 0.94)\n",
            "      5. Steelheart (The Reckoners) (Sim: 0.94)\n",
            "‚ùå MISS: 'Hyperion' (Key: hyperion) - Not in Top 100k Catalog.\n",
            "‚ùå MISS: 'The Lies of Locke Lamora' (Key: theliesoflockelamora) - Not in Top 100k Catalog.\n",
            "‚ùå MISS: 'The Fifth Season' (Key: thefifthseason) - Not in Top 100k Catalog.\n",
            "‚úÖ MATCH: 'Neuromancer' -> ID: 0441569595\n",
            "   ‚Ü≥ Based on this, you might like:\n",
            "      1. Cryptonomicon (Sim: 0.97)\n",
            "      2. Childhood's End: A Novel (Sim: 0.97)\n",
            "      3. A Fire Upon The Deep (Zones of Thought, 1) (Sim: 0.97)\n",
            "      4. Rendezvous with Rama (Sim: 0.97)\n",
            "      5. Ringworld: A Novel (Sim: 0.97)\n",
            "‚ùå MISS: 'The Blade Itself' (Key: thebladeitself) - Not in Top 100k Catalog.\n",
            "\n",
            "--- Summary: Found 5/10 books ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UKMf2g5Luy3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}